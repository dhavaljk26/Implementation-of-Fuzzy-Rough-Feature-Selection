{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries \n",
    "\n",
    "import numpy as np\n",
    "import skfuzzy as fuzz\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate  Łukasiewicz t_norm and  Łukasiewicz fuzzy_implicator, as given in \n",
    "# [Author: Richard Jensen, Qiang Shen, \n",
    "#  Paper : New Approaches to Fuzzy-Rough Feature Selection, \n",
    "#  Link  : https://ieeexplore.ieee.org/document/4505335]\n",
    "\n",
    "def t_norm(x, y):\n",
    "    return max(x+y-1.0, 0.0)\n",
    "\n",
    "def fuzzy_implicator(x, y):\n",
    "    return min(1.0-x+y, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fuzzy similarity measure for a particular attribute, as given in \n",
    "# [Author: Richard Jensen, Qiang Shen, \n",
    "#  Paper : New Approaches to Fuzzy-Rough Feature Selection, \n",
    "#  Link  : https://ieeexplore.ieee.org/document/4505335]\n",
    "\n",
    "def attribute_fuzzy_similarity_measure(arr):\n",
    "    \n",
    "    arr_2 = np.zeros( (arr.shape[0], arr.shape[0]) )\n",
    "    sigma = math.sqrt((np.var(arr, ddof=1)))\n",
    "    \n",
    "    if sigma == 0.0:\n",
    "        return np.ones( (arr.shape[0], arr.shape[0]) )\n",
    "    \n",
    "    for x in range(arr.shape[0]):\n",
    "        for y in range(arr.shape[0]):\n",
    "            arr_2[x][y] = arr_2[y][x] = max(0.0, min( float(arr[y]-arr[x]+sigma)/sigma, float(arr[x]+sigma-arr[y])/sigma))\n",
    "\n",
    "#     for i in range(arr_2.shape[0]):\n",
    "#         for j in range(arr_2.shape[0]):\n",
    "#             for k in range(arr_2.shape[0]):\n",
    "#                 arr_2[j][k] = max(arr_2[j][k], t_norm(arr_2[j][i], arr_2[i][k]))\n",
    "    return arr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate fuzzy similarity measure for a dataset for all attributes\n",
    "\n",
    "def fuzzy_similatity_measure(data):\n",
    "    fsm = np.zeros( (data.shape[1]-1, data.shape[0], data.shape[0]) )\n",
    "    data_transpose = np.transpose(data)\n",
    "    \n",
    "    for i in range(data.shape[1]-1):\n",
    "        fsm[i] = attribute_fuzzy_similarity_measure(data_transpose[i])\n",
    "    \n",
    "    return fsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate equivalence classes based on decision features\n",
    "\n",
    "def equivalence_class(data, decision_features):\n",
    "    E = dict()\n",
    "    s = data.shape\n",
    "    \n",
    "    for i in np.unique(np.transpose(data)[-1]):\n",
    "        E[int(i)] = set()\n",
    "        \n",
    "    for i in range(0, s[0]):\n",
    "        E[ int(data[i][s[1]-1]) ].add(i)\n",
    "                       \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if element is present in a set\n",
    "\n",
    "def present_in_set(s, element):\n",
    "    if element in s:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dependency measure of conditional features on data based on equivalence classes\n",
    "# [Note: dependency_measure is different for different modes, as given in paper]\n",
    "\n",
    "def dependency_measurement(data, conditional_features_set, equivalence_class, fsm, mode):\n",
    "    \n",
    "    mu_r = np.ones( (data.shape[0], data.shape[0]) )\n",
    "    \n",
    "    for i in conditional_features_set:\n",
    "        for x in range(data.shape[0]):\n",
    "            for y in range(data.shape[0]):\n",
    "                mu_r[x][y] = t_norm(mu_r[x][y], fsm[i][x][y])\n",
    "                \n",
    "    mu = np.zeros( (data.shape[0]) )\n",
    "    \n",
    "    if mode == 'boundary':\n",
    "        uncertainty = 0.0\n",
    "        for class_, eq_class in equivalence_class.items():\n",
    "            \n",
    "            for x in range(data.shape[0]):\n",
    "                I = 1.0\n",
    "                T = 0.0\n",
    "                for y in range(data.shape[0]):\n",
    "                    I = min(I, fuzzy_implicator(mu_r[x][y], present_in_set(eq_class, y))) \n",
    "                    T = max(T, t_norm(mu_r[x][y], present_in_set(eq_class, y)))\n",
    "                mu[x] = T - I\n",
    "            uncertainty += (np.sum(mu)/mu.size)/len(equivalence_class)\n",
    "        return 1.0 - uncertainty\n",
    "    else:\n",
    "        \n",
    "        for x in range(data.shape[0]):\n",
    "            for class_, eq_class in equivalence_class.items():\n",
    "                I = 1.0\n",
    "                for y in range(data.shape[0]):\n",
    "                    I = min(I, fuzzy_implicator(mu_r[x][y], present_in_set(eq_class, y))) \n",
    "\n",
    "                mu[x] = max(I, mu[x])  \n",
    "\n",
    "        return np.sum(mu)/mu.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy-Rough Quick Reduct as given in paper\n",
    "# [Note: Two modes are\n",
    "#        lower    :  Fuzzy Lower Approximation-Based FS\n",
    "#        boundary :  Fuzzy Boundary Region-Based FS]\n",
    "\n",
    "def fuzzy_rough_quick_reduct(data, conditional_features, decision_features, mode='lower'):\n",
    "    \n",
    "    if mode != 'lower' and mode != 'boundary':\n",
    "        print (\"Mode should be from ['lower', 'boundary']\")\n",
    "        return \n",
    "    \n",
    "    C = set(conditional_features)\n",
    "    D = set(decision_features)\n",
    "    R = set()\n",
    "    lambda_best = 0.0\n",
    "    lambda_prev = 0.00000001\n",
    "\n",
    "    fsm = fuzzy_similatity_measure(data)\n",
    "    equivalence_class_map = equivalence_class(data, decision_features)\n",
    "    while lambda_best != lambda_prev and lambda_best < 1.0:\n",
    "        T = R.copy()\n",
    "        lambda_prev = lambda_best\n",
    "        \n",
    "        lambda_T = dependency_measurement(data, T, equivalence_class_map, fsm, mode)\n",
    "        \n",
    "        lambda_max = lambda_T\n",
    "        feature_to_add = None\n",
    "        \n",
    "        C_minus_R = C.difference(R)\n",
    "        for x in C_minus_R:\n",
    "            temp = set()\n",
    "            temp = R.copy()\n",
    "            temp.add(x)\n",
    "            lambda_temp = dependency_measurement(data, temp, equivalence_class_map, fsm, mode)\n",
    "                        \n",
    "            if lambda_temp > lambda_max:\n",
    "                lambda_max = lambda_temp\n",
    "                feature_to_add = x\n",
    "         \n",
    "        if lambda_max > lambda_T and feature_to_add != None:\n",
    "            T.add(feature_to_add)\n",
    "            lambda_best = lambda_max\n",
    "            \n",
    "        R = T.copy()\n",
    "    return R    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example dataset given in paper (for testing)\n",
    "example_data = np.array([\n",
    "        [-0.4, -0.3, -0.5, 0], \n",
    "        [-0.4,  0.2, -0.1, 1], \n",
    "        [-0.3, -0.4, -0.3, 0], \n",
    "        [ 0.3, -0.3,  0.0, 1], \n",
    "        [ 0.2, -0.3,  0.0, 1], \n",
    "        [ 0.2,  0.0,  0.0, 0]\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "#Read from CSV\n",
    "data = pd.read_csv('new.csv',  header=None)\n",
    "\n",
    "#Remove missing values\n",
    "data = data.replace(-1, np.nan)\n",
    "data = data.dropna()\n",
    "\n",
    "#Convert dataframe to numpy matrix\n",
    "data_matrix = data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 3, 4, 6, 7, 9, 11}\n"
     ]
    }
   ],
   "source": [
    "# Calculate reduct set of attributes\n",
    "\n",
    "reduct = fuzzy_rough_quick_reduct(data_matrix, np.arange(data_matrix.shape[1]-1), np.array([data_matrix.shape[1]-1]), 'boundary')\n",
    "print(reduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy by comparing values of predicted and original values\n",
    "\n",
    "def measure_accuracy(pred, orig):\n",
    "    accuracy = 0\n",
    "    for i in range(len(pred)):\n",
    "            if pred[i] == orig[i]:\n",
    "                accuracy+=1\n",
    "    accuracy /= pred.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification using classifier parameter on whole dataset and dataset with reduct set of attributes\n",
    "\n",
    "def measure_classification_accuracy(classifier, data, reduct):\n",
    "    \n",
    "    c_train, c_test, d_train, d_test = train_test_split(data[:, :-1], data[:, -1:])\n",
    "    \n",
    "    C = set(np.arange(data.shape[1]-1))\n",
    "    rc_train = np.delete(c_train, list(C.difference(reduct)), 1)\n",
    "    rc_test = np.delete(c_test, list(C.difference(reduct)), 1)\n",
    "    \n",
    "    if classifier == 'DecisionTree':\n",
    "        from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "        dtree_model = DecisionTreeClassifier(max_depth = 20).fit(c_train, d_train) \n",
    "        dtree_predictions = dtree_model.predict(c_test)\n",
    "\n",
    "        rdtree_model = DecisionTreeClassifier(max_depth = 100).fit(rc_train, d_train) \n",
    "        rdtree_predictions = rdtree_model.predict(rc_test)\n",
    "\n",
    "        return measure_accuracy(dtree_predictions, d_test), measure_accuracy(rdtree_predictions, d_test)\n",
    "    \n",
    "    elif classifier == 'SVM':\n",
    "        from sklearn.svm import SVC \n",
    "        svm_model_linear = SVC(kernel = 'linear', C = 1).fit(c_train, d_train.ravel()) \n",
    "        svm_predictions = svm_model_linear.predict(c_test) \n",
    "\n",
    "        accuracy = svm_model_linear.score(c_test, d_test)\n",
    "        \n",
    "        rsvm_model_linear = SVC(kernel = 'linear', C = 1).fit(rc_train, d_train.ravel()) \n",
    "        rsvm_predictions = rsvm_model_linear.predict(rc_test) \n",
    "\n",
    "        reduct_accuracy = rsvm_model_linear.score(rc_test, d_test)\n",
    "        \n",
    "        return accuracy, reduct_accuracy\n",
    "    \n",
    "    elif classifier == 'KNN':\n",
    "        from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = 20).fit(c_train, d_train.ravel()) \n",
    "        accuracy = knn.score(c_test, d_test)\n",
    "        \n",
    "        rknn = KNeighborsClassifier(n_neighbors = 20).fit(rc_train, d_train.ravel()) \n",
    "        reduct_accuracy = rknn.score(rc_test, d_test)\n",
    "        \n",
    "        return accuracy, reduct_accuracy\n",
    "    \n",
    "    elif classifier == 'GaussianNaiveBayes':\n",
    "        from sklearn.naive_bayes import GaussianNB \n",
    "        \n",
    "        gnb = GaussianNB().fit(c_train, d_train.ravel()) \n",
    "        gnb_predictions = gnb.predict(c_test) \n",
    "        \n",
    "        rgnb = GaussianNB().fit(rc_train, d_train.ravel()) \n",
    "        rgnb_predictions = rgnb.predict(rc_test) \n",
    "      \n",
    "        return measure_accuracy(gnb_predictions, d_test), measure_accuracy(rgnb_predictions, d_test)\n",
    "\n",
    "    elif classifier == 'MultiLayerPerceptron':\n",
    "        from sklearn.neural_network import MLPClassifier\n",
    "        \n",
    "        mlp = MLPClassifier().fit(c_train, d_train.ravel())\n",
    "        mlp_predictions = mlp.predict(c_test)\n",
    "        \n",
    "        rmlp = MLPClassifier().fit(rc_train, d_train.ravel())\n",
    "        rmlp_predictions = rmlp.predict(rc_test)\n",
    "        \n",
    "        return measure_accuracy(mlp_predictions, d_test), measure_accuracy(rmlp_predictions, d_test)\n",
    "    \n",
    "    elif classifier == 'RandomForest':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        rf = RandomForestClassifier(n_estimators=10).fit(c_train, d_train.ravel())\n",
    "        rf_predictions = rf.predict(c_test)\n",
    "        \n",
    "        rrf = RandomForestClassifier(n_estimators=10).fit(rc_train, d_train.ravel())\n",
    "        rrf_predictions = rrf.predict(rc_test)\n",
    "        \n",
    "        return measure_accuracy(rf_predictions, d_test), measure_accuracy(rrf_predictions, d_test)\n",
    "        \n",
    "    else:\n",
    "        print ('Invalid parameter(classifier)')\n",
    "        return None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attributes accuracy    =  0.5733333333333334 \n",
      "Reduct attributes accuracy =  0.5866666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_accuracy, reduct_accuracy = measure_classification_accuracy('RandomForest', data_matrix, reduct)\n",
    "print (\"All attributes accuracy    = \",all_accuracy, \"\\nReduct attributes accuracy = \",reduct_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
